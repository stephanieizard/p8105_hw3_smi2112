---
title: "p8105_hw3_smi2112"
author: "Stephanie Izard"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(ggridges)
```

##Problem 1

Loading BRFSS data from p8105.datasets package:

```{r cache = TRUE}
brfss <- p8105.datasets::brfss_smart2010
```

Data cleaning: Use appropriate names, focus on the "Overall Health" topic, include only responses from "Excellent" to "Poor", organize responses as a factor taking levels ordered from "Excellent" to "Poor".

```{r}
brfss = brfss %>% 
  janitor::clean_names() %>% 
  rename(state = locationabbr, county = locationdesc) %>% 
  filter(topic == "Overall Health") %>% 
  mutate(response = forcats::fct_relevel(response, c("Excellent", "Very good", "Good", "Fair","Poor")))
```

Question: In 2002, which states were observed at 7 locations?
Answer: 3 states were observed at exactly 7 distinct locations in 2002: CT, FL, and NC.

```{r}
brfss %>% 
  filter(year == 2002) %>% 
  select(state, county) %>% 
  group_by(state) %>% 
  distinct() %>% 
  count(state) %>% 
  filter(n == 7) %>% 
  rename("State" = state, "Number of Locations" = n) %>% 
  knitr::kable()
```

Spaghetti plot showing the number of distinct locations in each state from 2002 to 2010:

```{r}
brfss %>%
  select(year, state, county) %>% 
  distinct(year, state, county) %>% 
  group_by(year, state) %>% 
  mutate(locations = n()) %>% 
  ggplot(aes(x = year, y = locations, color = state)) +
    geom_line() +
    labs(title = "Number of locations in each state from 2002 to 2010", x = "Year", y = "Number of locations") +
    viridis::scale_color_viridis(option = "viridis", discrete = TRUE) +
    theme_bw()
```

Table showing for the years 2002, 2006, and 2010 the mean and std of the proportion of "Execllent" responses across locations in NYS:

```{r}
brfss %>% 
  filter(state == "NY") %>% 
  filter(year == 2002 | year == 2006 | year == 2010) %>% 
  select(year, county, response) %>% 
  group_by(year) %>% 
  summarize("Mean" = mean(response == "Excellent"), "Std" = sd(response == "Excellent")) %>% 
  rename("Year" = year) %>% 
  knitr::kable()
```

For each year and state, the average proportion in each response category:

```{r}
brfss %>%
  select(year, state, response, data_value) %>%
  rename(proportion = data_value) %>% 
  mutate(year = as.factor(year)) %>% 
  group_by(year, state, response) %>% 
  summarize(mean_prop = mean(proportion))
```

A five-panel plot showing the distribution of the above state level averages over time:

```{r}
brfss %>%
  select(year, state, response, data_value) %>%
  rename(proportion = data_value) %>% 
  mutate(year = as.factor(year)) %>% 
  group_by(year, state, response) %>% 
  summarize(mean_prop = mean(proportion)) %>% 
  ggplot(aes(x = mean_prop, y = year)) +
    geom_density_ridges(scale = 1, fill = "darkslateblue") +
    facet_grid(~ response) +
    labs(title = "Average proportion of responses by year", x = "Proportion", y = "Year") + 
    theme_bw()
```

##Problem 2

Loading instacart data:

```{r cache = TRUE}
instacart <- p8105.datasets::instacart
```

Short description of dataset:

The size of the dataset is `r dim(instacart)` (1384617 observations/ rows and 15 variables/ columns) and is in long format. The variable "order_id" is a number unique to each individual order, the variable "order_dow" is the day of the week the order was placed (0 = Sunday), "order_hour_of_day" is the hour of the day when the order was placed, "product_name" is the product name, "aisle_id" is a number unique to each aisle, and "aisle" is the name of the aisle. The dataset, "The Instacart Online Grocery Shopping Dataset 2017", comes from Instacart, an online grocery service. There were `r instacart %>% select(order_id) %>% n_distinct()` unique order identification numbers. `r instacart %>% select(order_dow) %>% filter(order_dow == 0) %>% group_by(order_dow) %>% summarize(n())` total products were ordered on a Sunday. 

Number of aisles, most popular aisles:

There are 134 different aisles in the store. Aisle number 83 has the most items ordered from it, with a total of 150609 products. Aisle number 24 has the second most items ordered from it, with a total of 150473 products.

```{r}
instacart %>% 
  select(aisle_id) %>% 
  n_distinct()

instacart %>% 
  select(aisle_id) %>% 
  group_by(aisle_id) %>% 
  count(aisle_id) %>% 
  arrange(desc(n))
```

Plot showing the number of items ordered in each aisle:
  
```{r}
instacart %>% 
  select(aisle) %>% 
  group_by(aisle) %>% 
  summarize(n = n()) %>% 
  mutate(aisle = forcats::fct_reorder(aisle, n)) %>% 
  arrange(desc(n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
    geom_histogram(stat = "identity", fill = "darkslateblue") +
    scale_y_continuous(limits = c(0, 150700), breaks = c(0, 25000, 50000, 75000, 100000, 125000, 150000)) + 
    labs(title = "Number of orders per aisle", x = "Aisle", y = "Number of orders") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Table showing most popular items for "baking ingredients", "dog food care", and "packaged vegetables fruits":

```{r}
instacart %>% 
  filter(aisle == "baking ingredients" | aisle == "dog food care" | aisle == "packaged vegetables fruits") %>% 
  select(aisle, product_name, order_id) %>% 
  group_by(aisle, product_name) %>% 
  summarize(n = n()) %>% 
  filter(n == max(n)) %>% 
  rename("Aisle" = aisle, "Most Popular Product" = product_name, "Number of Orders" = n) %>% 
  knitr::kable()
```

Table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week:

```{r}
instacart %>% 
  select(product_name, order_hour_of_day, order_dow) %>%
  mutate(order_dow = factor(order_dow, levels = c(0,1,2,3,4,5,6), labels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))) %>% 
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>% 
  group_by(product_name, order_dow) %>% 
  summarize(hour_mean = mean(order_hour_of_day)) %>% 
  spread(key = order_dow, value = hour_mean) %>% 
  rename("Product Name" = product_name) %>% 
  knitr::kable()
```

##Problem 3

Loading NY NOAA data:

```{r cache = TRUE}
ny_noaa <- p8105.datasets::ny_noaa
```

Short description of dataset:

The size of the dataset is `r dim(ny_noaa)` (2595176 observations/ rows and 7 variables/ columns) and is in long format. The variable "id" is weather station ID, "date" is the date of observation, "prcp" is amount of precipitation measured in tenth of mm, "snow" is amount of snowfall measured in mm, "snwd" is snow depth measured in mm, "tmax" is the maximum temperature measured in tenths of degrees C, and "tmin" is the minimum temperature measured in tenths of degrees C. The dataset contains extensive missing data, as each weather station may only collect a subset of these variables. The table created below (missing_data) summarizes the proportion of missing variables at each station.

```{r}
missing_data <- ny_noaa %>% 
  group_by(id) %>% 
  summarize_all(funs(mean(is.na(.))))
```

Data cleaning:

```{r}
ny_noaa <- ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(year, as.integer(year)) %>%
  mutate_at(vars(prcp:tmin), as.numeric) %>% 
  mutate(tmax = tmax / 10,
         tmin = tmin / 10,
         prcp = prcp / 100, 
         snow = snow / 10, 
         snwd = snwd / 10)
```

Date was sepparated into year, month, and day. Maximum and minimum temperature were changed from tenths of degrees C to degrees C. Precipitation was changed from tenths of a mm to cm. Snowfall and snow depth were changed from mm to cm.

The most commonly observed snowfall value is 0 cm. The second most commonly observed snowfall is 2.5 cm.

```{r}
ny_noaa %>% 
  group_by(snow) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n))
```

Two-panel plot showing the average max temperature in January and in July in each station across years:

```{r}
ny_noaa %>% 
  filter(month == "01" | month == "07") %>% 
  mutate(month = if_else(month == "01", "January", "July")) %>% 
  group_by(id, year, month) %>% 
  summarize(avg_tmax = mean(tmax, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = avg_tmax, group = id)) +
  geom_line(color = "darkslateblue") +
  facet_grid(~ month) +
  labs(title = "Average maximum temperature at each site in January and July from 1981 to 2010 in NYS", x = "Year", y = "Temperature (Degrees C)") +
  theme_bw()
```

Two-panel plot showing (i) tmax vs tmin for the full dataset and (ii) the distribution of snowfall values between 0 and 100 separately by year.

```{r}
library(patchwork)

plot1 <- ggplot(ny_noaa, aes(x = tmax, y = tmin)) +
  geom_hex() +
  labs(title = "Maximum by minimum temperature", x = "Maximum temperature (Degrees C)", y = "Minimum temperature (Degrees C)") +
  viridis::scale_fill_viridis(option = "plasma") + 
  theme_bw()

plot2 <- ny_noaa %>% 
  filter(snow >= 0 & snow <= 100) %>% 
  ggplot(aes(x = snow, y = year)) +
  geom_density_ridges(scale = 0.9, fill = "darkred") + 
  labs(title = "Snow fall distribution per year", x = "Snowfall (cm)", y = "Year") +
  theme_bw()

plot1 + plot2
```













